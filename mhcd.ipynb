{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training diffusion model...\n",
      "Epoch 1/10 - Loss: 0.1047\n",
      "Epoch 2/10 - Loss: 0.0763\n",
      "Epoch 3/10 - Loss: 0.0743\n",
      "Epoch 4/10 - Loss: 0.0735\n",
      "Epoch 5/10 - Loss: 0.0718\n",
      "Epoch 6/10 - Loss: 0.0729\n",
      "Epoch 7/10 - Loss: 0.0722\n",
      "Epoch 8/10 - Loss: 0.0722\n",
      "Epoch 9/10 - Loss: 0.0718\n",
      "Epoch 10/10 - Loss: 0.0706\n",
      "Diffusion model training completed.\n",
      "\n",
      "Running planning search...\n",
      "\n",
      "Planned trajectory length: 1\n",
      "Step 0: [0. 0. 0. 0.]\n",
      "Final reward (negative distance): -2.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import random\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(state_dim + 1, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, state_dim)\n",
    "    \n",
    "    def forward(self, noisy_state, noise_level):\n",
    "        # Dimension unification handling\n",
    "        if noisy_state.dim() == 1:\n",
    "            noisy_state = noisy_state.unsqueeze(0)\n",
    "        if noise_level.dim() == 0:\n",
    "            noise_level = noise_level.unsqueeze(0).unsqueeze(1)\n",
    "        elif noise_level.dim() == 1:\n",
    "            noise_level = noise_level.unsqueeze(1)\n",
    "            \n",
    "        x = torch.cat([noisy_state, noise_level], dim=-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x).squeeze(0)\n",
    "\n",
    "class SyntheticTrajectoryDataset(Dataset):\n",
    "    def __init__(self, num_samples, state_dim):\n",
    "        self.num_samples = num_samples\n",
    "        self.state_dim = state_dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        clean_state = torch.rand(self.state_dim)\n",
    "        noise_level = random.choice([0.5, 1.0])\n",
    "        return (clean_state + torch.randn(self.state_dim) * noise_level,\n",
    "                torch.tensor(noise_level, dtype=torch.float32),\n",
    "                clean_state)\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, trajectory, noise_level, parent=None, meta_action=0):\n",
    "        self.trajectory = trajectory\n",
    "        self.noise_level = noise_level\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.visit_count = 0\n",
    "        self.value = 0.0\n",
    "        self.meta_action_weights = torch.tensor([1.0, 1.0])  # Initial weights for 2 meta-actions\n",
    "        self.action_history = []\n",
    "\n",
    "class MCTDPlanner:\n",
    "    def __init__(self, diffusion_model, goal, planning_horizon, state_dim, device):\n",
    "        self.diffusion_model = diffusion_model.to(device)\n",
    "        self.goal = goal.to(device)\n",
    "        self.planning_horizon = planning_horizon\n",
    "        self.state_dim = state_dim\n",
    "        self.device = device\n",
    "        self.root = Node([], torch.tensor(1.0, device=device))\n",
    "\n",
    "    def uct_score(self, parent, child, c_param=1.41):\n",
    "        if child.visit_count == 0:\n",
    "            return float('inf')\n",
    "        return (child.value / child.visit_count) + \\\n",
    "               c_param * math.sqrt(math.log(parent.visit_count + 1) / child.visit_count)\n",
    "\n",
    "    def best_uct_child(self, node):\n",
    "        return node.children[max(enumerate(\n",
    "            [self.uct_score(node, child) for child in node.children]),\n",
    "            key=lambda x: x[1])[0]]\n",
    "\n",
    "    def is_fully_expanded(self, node):\n",
    "        return len(node.children) >= 2  # Two meta-actions available\n",
    "\n",
    "    def is_leaf(self, node):\n",
    "        return len(node.trajectory) >= self.planning_horizon\n",
    "\n",
    "    def select_meta_action(self, node):\n",
    "        # Softmax selection based on learned weights\n",
    "        probs = F.softmax(node.meta_action_weights, dim=0)\n",
    "        return torch.multinomial(probs, 1).item()\n",
    "\n",
    "    def denoise_subplan(self, node, meta_action):\n",
    "        # Generate subplan using meta-action guidance\n",
    "        with torch.no_grad():\n",
    "            noise_level = node.noise_level * 0.8  # Noise reduction\n",
    "            return [self.diffusion_model(\n",
    "                node.trajectory[-1].to(self.device) if node.trajectory \n",
    "                else torch.randn(self.state_dim, device=self.device),\n",
    "                noise_level.to(self.device)\n",
    "            )]\n",
    "\n",
    "    def create_node(self, subplan):\n",
    "        return Node(\n",
    "            trajectory=subplan,\n",
    "            noise_level=subplan[-1].mean(),\n",
    "            parent=None\n",
    "        )\n",
    "\n",
    "    def update_meta_schedule(self, node, reward):\n",
    "        # Update meta-action weights using reward signal\n",
    "        learning_rate = 0.1\n",
    "        if node.action_history:\n",
    "            last_action = node.action_history[-1]\n",
    "            node.meta_action_weights[last_action] += learning_rate * reward\n",
    "            node.meta_action_weights = torch.clamp(node.meta_action_weights, 0.1, 10.0)\n",
    "\n",
    "    def fast_denoising(self, partial_trajectory):\n",
    "        if len(partial_trajectory) >= self.planning_horizon:\n",
    "            return []\n",
    "            \n",
    "        num_steps = self.planning_horizon - len(partial_trajectory)\n",
    "        current_state = partial_trajectory[-1].clone() if partial_trajectory \\\n",
    "            else torch.randn(self.state_dim, device=self.device)\n",
    "            \n",
    "        noise_schedule = torch.linspace(0.5, 0.01, 5, device=self.device)\n",
    "        denoised = []\n",
    "        \n",
    "        for _ in range(num_steps):\n",
    "            for t in noise_schedule:\n",
    "                current_state = self.diffusion_model(\n",
    "                    current_state.unsqueeze(0),\n",
    "                    t.unsqueeze(0)\n",
    "                ).squeeze(0)\n",
    "            denoised.append(current_state.clone())\n",
    "            \n",
    "        return denoised\n",
    "\n",
    "    def evaluate_plan(self, full_plan):\n",
    "        final_state = full_plan[-1].to(self.device)\n",
    "        return -torch.norm(final_state - self.goal).item()\n",
    "\n",
    "    def search(self, iterations):\n",
    "        for _ in range(iterations):\n",
    "            node = self.root\n",
    "            # Selection phase\n",
    "            while self.is_fully_expanded(node) and not self.is_leaf(node):\n",
    "                node = self.best_uct_child(node)\n",
    "\n",
    "            # Expansion phase\n",
    "            if not self.is_leaf(node):\n",
    "                meta_action = self.select_meta_action(node)\n",
    "                node.action_history.append(meta_action)\n",
    "                subplan = self.denoise_subplan(node, meta_action)\n",
    "                child = self.create_node(subplan)\n",
    "                node.children.append(child)\n",
    "                node = child\n",
    "\n",
    "            # Simulation phase\n",
    "            full_plan = node.trajectory + self.fast_denoising(node.trajectory)\n",
    "            reward = self.evaluate_plan(full_plan)\n",
    "\n",
    "            # Backpropagation\n",
    "            current = node\n",
    "            while current is not None:\n",
    "                current.visit_count += 1\n",
    "                current.value += reward\n",
    "                self.update_meta_schedule(current, reward)\n",
    "                current = current.parent\n",
    "\n",
    "        # Return best trajectory\n",
    "        best_child = max(self.root.children, key=lambda x: x.value/x.visit_count)\n",
    "        return best_child.trajectory\n",
    "\n",
    "def train_diffusion_model(model, device, dataloader, epochs=5, lr=1e-3):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0.0\n",
    "        for noisy_state, noise_level, clean_state in dataloader:\n",
    "            noisy_state = noisy_state.to(device)\n",
    "            noise_level = noise_level.to(device)\n",
    "            clean_state = clean_state.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(noisy_state, noise_level)\n",
    "            loss = loss_fn(output, clean_state)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch}/{epochs} - Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    state_dim = 4\n",
    "    hidden_dim = 32\n",
    "    num_train_samples = 10000\n",
    "    batch_size = 128\n",
    "    train_epochs = 10\n",
    "    planning_horizon = 10\n",
    "    \n",
    "    # Dataset and model setup\n",
    "    dataset = SyntheticTrajectoryDataset(num_train_samples, state_dim)\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "    \n",
    "    diffusion_model = DiffusionModel(state_dim, hidden_dim).to(device)\n",
    "    print(\"Training diffusion model...\")\n",
    "    train_diffusion_model(diffusion_model, device, dataloader, train_epochs)\n",
    "    print(\"Diffusion model training completed.\\n\")\n",
    "\n",
    "    # Planning setup\n",
    "    goal = torch.ones(state_dim, device=device)\n",
    "    planner = MCTDPlanner(diffusion_model, goal, planning_horizon, state_dim, device)\n",
    "    \n",
    "    print(\"Running planning search...\")\n",
    "    best_traj = planner.search(100)\n",
    "    \n",
    "    # Results display\n",
    "    if not best_traj:\n",
    "        print(\"No valid trajectory found\")\n",
    "    else:\n",
    "        print(f\"\\nPlanned trajectory length: {len(best_traj)}\")\n",
    "        for t, state in enumerate(best_traj):\n",
    "            print(f\"Step {t}: {state.cpu().detach().numpy().round(3)}\")\n",
    "        final_reward = -torch.norm(best_traj[-1] - goal, p=2).item()\n",
    "        print(f\"Final reward (negative distance): {final_reward:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
