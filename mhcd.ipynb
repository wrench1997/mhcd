{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training diffusion model...\n",
      "Epoch 1/10 - Loss: 0.1501\n",
      "Epoch 2/10 - Loss: 0.0769\n",
      "Epoch 3/10 - Loss: 0.0734\n",
      "Epoch 4/10 - Loss: 0.0729\n",
      "Epoch 5/10 - Loss: 0.0733\n",
      "Epoch 6/10 - Loss: 0.0736\n",
      "Epoch 7/10 - Loss: 0.0729\n",
      "Epoch 8/10 - Loss: 0.0731\n",
      "Epoch 9/10 - Loss: 0.0718\n",
      "Epoch 10/10 - Loss: 0.0731\n",
      "Diffusion model training completed.\n",
      "\n",
      "Running planning search...\n",
      "\n",
      "Planned trajectory length: 2\n",
      "Step 0: [0.427 0.466 0.284 0.551]\n",
      "Step 1: [0.479 0.487 0.47  0.497]\n",
      "Final reward (negative distance): -1.034\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import random\n",
    "\n",
    "class MetaPolicy(nn.Module):\n",
    "    def __init__(self, state_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(state_dim + 1, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, state, noise_level):\n",
    "        x = torch.cat([state, noise_level.unsqueeze(-1)], dim=-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(state_dim + 1, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, state_dim)\n",
    "    \n",
    "    def forward(self, noisy_state, noise_level):\n",
    "        if noisy_state.dim() == 1:\n",
    "            noisy_state = noisy_state.unsqueeze(0)\n",
    "        noise_level = noise_level.view(-1, 1)\n",
    "            \n",
    "        x = torch.cat([noisy_state, noise_level], dim=-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x).squeeze(0)\n",
    "\n",
    "class SyntheticTrajectoryDataset(Dataset):\n",
    "    def __init__(self, num_samples, state_dim):\n",
    "        self.num_samples = num_samples\n",
    "        self.state_dim = state_dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        clean_state = torch.rand(self.state_dim)\n",
    "        noise_level = random.choice([0.5, 1.0])\n",
    "        return (clean_state + torch.randn(self.state_dim) * noise_level,\n",
    "                torch.tensor(noise_level, dtype=torch.float32),\n",
    "                clean_state)\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, trajectory, noise_level, parent=None, device='cuda'):\n",
    "        self.device = device\n",
    "        self.trajectory = [t.detach().requires_grad_(False) for t in trajectory] if parent else trajectory\n",
    "        self.noise_level = noise_level.detach().to(self.device)\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.visit_count = 0\n",
    "        self.value = 0.0\n",
    "        self.meta_policy = MetaPolicy(len(self.trajectory[-1])).to(device)\n",
    "        self.optimizer = optim.Adam(self.meta_policy.parameters(), lr=0.001)\n",
    "\n",
    "    def update_policy(self, reward):\n",
    "        if not self.trajectory:\n",
    "            return\n",
    "            \n",
    "        self.optimizer.zero_grad()\n",
    "        policy_logits = self.meta_policy(self.trajectory[-1], self.noise_level)\n",
    "        loss = -reward * F.log_softmax(policy_logits, dim=-1)[0]\n",
    "        loss.backward(retain_graph=False)\n",
    "        self.optimizer.step()\n",
    "\n",
    "class MCTDPlanner:\n",
    "    def __init__(self, diffusion_model, goal, planning_horizon, state_dim, device):\n",
    "        self.diffusion_model = diffusion_model.to(device)\n",
    "        self.goal = goal.to(device)\n",
    "        self.planning_horizon = planning_horizon\n",
    "        self.state_dim = state_dim\n",
    "        self.device = device\n",
    "        self.root = Node([torch.randn(state_dim, device=device)], \n",
    "                        torch.tensor(1.0, device=device),\n",
    "                        device=device)\n",
    "\n",
    "    def cosine_schedule(self, t, T, s=0.008):\n",
    "        return torch.cos((t / T + s) / (1 + s) * math.pi / 2) ** 2\n",
    "\n",
    "    def uct_score(self, parent, child, c_param=1.41):\n",
    "        exploration = c_param * math.sqrt(math.log(parent.visit_count + 1) / (child.visit_count + 1e-8))\n",
    "        noise_penalty = child.noise_level * math.log(self.planning_horizon + 1)\n",
    "        return (child.value / (child.visit_count + 1e-8)) + exploration - noise_penalty\n",
    "\n",
    "    def best_uct_child(self, node):\n",
    "        scores = [self.uct_score(node, child) for child in node.children]\n",
    "        return node.children[torch.argmax(torch.tensor(scores)).item()]\n",
    "\n",
    "    def is_fully_expanded(self, node):\n",
    "        return len(node.children) >= 2\n",
    "\n",
    "    def is_leaf(self, node):\n",
    "        return len(node.trajectory) >= self.planning_horizon\n",
    "\n",
    "    def select_meta_action(self, node):\n",
    "        with torch.no_grad():\n",
    "            logits = node.meta_policy(node.trajectory[-1], node.noise_level)\n",
    "            return torch.distributions.Categorical(logits=logits).sample().item()\n",
    "\n",
    "    def denoise_subplan(self, node, meta_action):\n",
    "        device = node.device\n",
    "        subplan = []\n",
    "        num_steps = meta_action + 1\n",
    "        noise_decay = 0.5 + 0.3 * meta_action\n",
    "        \n",
    "        current_state = node.trajectory[-1].clone()\n",
    "        current_noise = node.noise_level * noise_decay\n",
    "        \n",
    "        for step in range(num_steps):\n",
    "            t = torch.tensor(step / num_steps, device=device)\n",
    "            noise_level = self.cosine_schedule(t, num_steps)\n",
    "            current_state = self.diffusion_model(\n",
    "                current_state.unsqueeze(0),\n",
    "                noise_level.unsqueeze(0)\n",
    "            ).squeeze(0)\n",
    "            subplan.append(current_state.detach())\n",
    "        \n",
    "        return subplan\n",
    "\n",
    "    def create_node(self, subplan, parent):\n",
    "        device = parent.device if parent else self.device\n",
    "        subplan = [s.to(device) for s in subplan]\n",
    "        return Node(\n",
    "            trajectory=subplan,\n",
    "            noise_level=subplan[-1].mean().detach(),\n",
    "            parent=parent,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "    def fast_denoising(self, partial_trajectory):\n",
    "        if len(partial_trajectory) >= self.planning_horizon:\n",
    "            return []\n",
    "            \n",
    "        remaining_steps = self.planning_horizon - len(partial_trajectory)\n",
    "        current_state = partial_trajectory[-1].clone() if partial_trajectory else torch.randn(self.state_dim, device=self.device)\n",
    "        denoised = []\n",
    "        \n",
    "        T = 5 * remaining_steps\n",
    "        for step in range(remaining_steps):\n",
    "            t = torch.tensor(step / remaining_steps, device=self.device)\n",
    "            noise_level = self.cosine_schedule(t, T)\n",
    "            current_state = self.diffusion_model(\n",
    "                current_state.unsqueeze(0),\n",
    "                noise_level.unsqueeze(0)\n",
    "            ).squeeze(0)\n",
    "            denoised.append(current_state.detach())\n",
    "            \n",
    "        return denoised\n",
    "\n",
    "    def evaluate_plan(self, full_plan):\n",
    "        final_state = full_plan[-1].to(self.device)\n",
    "        return -torch.norm(final_state - self.goal).item()\n",
    "\n",
    "    def search(self, iterations):\n",
    "        for _ in range(iterations):\n",
    "            node = self.root\n",
    "            \n",
    "            # Selection phase\n",
    "            while self.is_fully_expanded(node) and not self.is_leaf(node):\n",
    "                node = self.best_uct_child(node)\n",
    "            \n",
    "            # Expansion phase\n",
    "            if not self.is_leaf(node):\n",
    "                meta_action = self.select_meta_action(node)\n",
    "                subplan = self.denoise_subplan(node, meta_action)\n",
    "                child = self.create_node(subplan, parent=node)\n",
    "                node.children.append(child)\n",
    "                node = child\n",
    "            \n",
    "            # Simulation phase\n",
    "            full_plan = node.trajectory + self.fast_denoising(node.trajectory)\n",
    "            reward = self.evaluate_plan(full_plan)\n",
    "            \n",
    "            # Backpropagation\n",
    "            current_node = node\n",
    "            while current_node is not None:\n",
    "                current_node.visit_count += 1\n",
    "                current_node.value += reward\n",
    "                current_node.update_policy(reward)\n",
    "                current_node = current_node.parent\n",
    "        \n",
    "        best_child = max(self.root.children, key=lambda x: x.value/(x.visit_count + 1e-8))\n",
    "        return best_child.trajectory\n",
    "\n",
    "def train_diffusion_model(model, device, dataloader, epochs=5, lr=1e-3):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0.0\n",
    "        for noisy_state, noise_level, clean_state in dataloader:\n",
    "            noisy_state = noisy_state.to(device)\n",
    "            noise_level = noise_level.to(device)\n",
    "            clean_state = clean_state.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(noisy_state, noise_level) \n",
    "            loss = loss_fn(output, clean_state)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch}/{epochs} - Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    state_dim = 4\n",
    "    hidden_dim = 32\n",
    "    num_train_samples = 10000\n",
    "    batch_size = 128\n",
    "    train_epochs = 10\n",
    "    planning_horizon = 10\n",
    "    \n",
    "    dataset = SyntheticTrajectoryDataset(num_train_samples, state_dim)\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "    \n",
    "    diffusion_model = DiffusionModel(state_dim, hidden_dim).to(device)\n",
    "    print(\"Training diffusion model...\")\n",
    "    train_diffusion_model(diffusion_model, device, dataloader, train_epochs)\n",
    "    print(\"Diffusion model training completed.\\n\")\n",
    "    \n",
    "    goal = torch.ones(state_dim, device=device)\n",
    "    planner = MCTDPlanner(diffusion_model, goal, planning_horizon, state_dim, device)\n",
    "    \n",
    "    print(\"Running planning search...\")\n",
    "    best_traj = planner.search(100)\n",
    "    \n",
    "    if not best_traj:\n",
    "        print(\"No valid trajectory found\")\n",
    "    else:\n",
    "        print(f\"\\nPlanned trajectory length: {len(best_traj)}\")\n",
    "        for t, state in enumerate(best_traj):\n",
    "            print(f\"Step {t}: {state.cpu().detach().numpy().round(3)}\")\n",
    "        final_reward = -torch.norm(best_traj[-1] - goal, p=2).item()\n",
    "        print(f\"Final reward (negative distance): {final_reward:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
