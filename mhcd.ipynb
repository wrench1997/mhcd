{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training diffusion model...\n",
      "Epoch 1/10 - Loss: 0.1047\n",
      "Epoch 2/10 - Loss: 0.0763\n",
      "Epoch 3/10 - Loss: 0.0743\n",
      "Epoch 4/10 - Loss: 0.0735\n",
      "Epoch 5/10 - Loss: 0.0718\n",
      "Epoch 6/10 - Loss: 0.0729\n",
      "Epoch 7/10 - Loss: 0.0722\n",
      "Epoch 8/10 - Loss: 0.0722\n",
      "Epoch 9/10 - Loss: 0.0718\n",
      "Epoch 10/10 - Loss: 0.0706\n",
      "Diffusion model training completed.\n",
      "\n",
      "Running planning search...\n",
      "\n",
      "Planned trajectory length: 1\n",
      "Step 0: [0. 0. 0. 0.]\n",
      "Final reward (negative distance): -2.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import random\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim + 1, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, state_dim)\n",
    "    \n",
    "    def forward(self, noisy_state, noise_level):\n",
    "        # Dimension unification handling\n",
    "        if noisy_state.dim() == 1:\n",
    "            noisy_state = noisy_state.unsqueeze(0)\n",
    "        if noise_level.dim() == 0:\n",
    "            noise_level = noise_level.unsqueeze(0).unsqueeze(1)\n",
    "        elif noise_level.dim() == 1:\n",
    "            noise_level = noise_level.unsqueeze(1)\n",
    "            \n",
    "        x = torch.cat([noisy_state, noise_level], dim=-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        denoised = self.fc3(x)\n",
    "        return denoised.squeeze(0)  # Remove batch dimension\n",
    "\n",
    "class SyntheticTrajectoryDataset(Dataset):\n",
    "    def __init__(self, num_samples, state_dim):\n",
    "        self.num_samples = num_samples\n",
    "        self.state_dim = state_dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate synthetic data with random noise\n",
    "        clean_state = torch.rand(self.state_dim)\n",
    "        noise_level = random.choice([0.5, 1.0])\n",
    "        noise = torch.randn(self.state_dim) * noise_level\n",
    "        noisy_state = clean_state + noise\n",
    "        return noisy_state, torch.tensor(noise_level, dtype=torch.float32), clean_state\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, trajectory, noise_level, parent=None, meta_action=0):\n",
    "        self.trajectory = trajectory  \n",
    "        self.noise_level = noise_level\n",
    "        self.parent = parent\n",
    "        self.meta_action = meta_action\n",
    "        self.children = []\n",
    "        self.visit_count = 0\n",
    "        self.value = 0.0\n",
    "        self.is_terminal = False\n",
    "\n",
    "    def add_child(self, child_node):\n",
    "        self.children.append(child_node)\n",
    "\n",
    "class MCTDPlanner:\n",
    "    def __init__(self, diffusion_model, goal, planning_horizon, state_dim, device):\n",
    "        self.diffusion_model = diffusion_model.to(device)\n",
    "        self.goal = goal.to(device)\n",
    "        self.planning_horizon = planning_horizon\n",
    "        self.state_dim = state_dim\n",
    "        self.device = device\n",
    "        self.root = Node(trajectory=[], noise_level=torch.tensor(1.0, device=device), parent=None)\n",
    "\n",
    "    def uct_score(self, parent, child, c_param=1.41):\n",
    "        if child.visit_count == 0:\n",
    "            return float('inf')\n",
    "        exploitation = child.value / child.visit_count\n",
    "        exploration = c_param * math.sqrt(math.log(parent.visit_count + 1) / child.visit_count)\n",
    "        return exploitation + exploration\n",
    "\n",
    "    def best_uct_child(self, node):\n",
    "        scores = [self.uct_score(node, child) for child in node.children]\n",
    "        return node.children[scores.index(max(scores))]\n",
    "\n",
    "    def is_fully_expanded(self, node):\n",
    "        return len(node.children) == 2\n",
    "\n",
    "    def is_leaf(self, node):\n",
    "        return len(node.children) == 0\n",
    "\n",
    "    def is_expandable(self, node):\n",
    "        return not self.is_fully_expanded(node)\n",
    "\n",
    "    def select_meta_action(self, node):\n",
    "        # Smarter meta-action selection\n",
    "        if node.trajectory:\n",
    "            last_state = node.trajectory[-1]\n",
    "            return 0 if last_state.mean() > 0.5 else 1\n",
    "        return 0\n",
    "\n",
    "    def denoise_subplan(self, node, meta_action):\n",
    "        return [torch.zeros(self.state_dim, device=self.device)]\n",
    "\n",
    "    def create_node(self, subplan):\n",
    "        return Node(trajectory=subplan, \n",
    "                   noise_level=subplan[-1].mean(),\n",
    "                   parent=None)\n",
    "\n",
    "    def fast_denoising(self, partial_trajectory):\n",
    "        \"\"\"Complete denoising with dimension fixes\"\"\"\n",
    "        if not partial_trajectory:\n",
    "            return []\n",
    "        \n",
    "        num_denoise_steps = 5\n",
    "        device = self.device\n",
    "        current_state = partial_trajectory[-1].detach().clone().to(device)\n",
    "        remaining_steps = self.planning_horizon - len(partial_trajectory)\n",
    "        \n",
    "        # Add batch dimension\n",
    "        current_state = current_state.unsqueeze(0)  # [1, state_dim]\n",
    "        \n",
    "        # Noise scheduling (exponential decay)\n",
    "        initial_noise_level = 0.5\n",
    "        noise_schedule = torch.exp(\n",
    "            torch.linspace(\n",
    "                math.log(initial_noise_level), \n",
    "                math.log(1e-3), \n",
    "                num_denoise_steps,\n",
    "                device=device\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        denoised_states = []\n",
    "        for step in range(remaining_steps):\n",
    "            noisy_state = current_state\n",
    "            for t in range(num_denoise_steps):\n",
    "                # Dynamic noise adjustment\n",
    "                adjusted_noise = noise_schedule[t] * (1 - step/remaining_steps)\n",
    "                adjusted_noise = adjusted_noise.unsqueeze(0).unsqueeze(1)  # [1,1]\n",
    "                \n",
    "                # Denoising step\n",
    "                with torch.no_grad():\n",
    "                    denoised = self.diffusion_model(\n",
    "                        noisy_state, \n",
    "                        adjusted_noise.to(device)\n",
    "                    ).unsqueeze(0)  # Maintain batch dimension\n",
    "                \n",
    "                # Momentum update\n",
    "                if t < num_denoise_steps - 1:\n",
    "                    noisy_state = 0.8 * denoised + 0.2 * noisy_state\n",
    "                else:\n",
    "                    current_state = denoised\n",
    "                    \n",
    "            # Remove batch dimension and store\n",
    "            denoised_states.append(current_state.squeeze(0).clone())\n",
    "            \n",
    "        return denoised_states\n",
    "\n",
    "    def evaluate_plan(self, full_plan):\n",
    "        final_state = full_plan[-1].to(self.device)\n",
    "        return -torch.norm(final_state - self.goal, p=2).item()\n",
    "\n",
    "    def search(self, iterations):\n",
    "        for _ in range(iterations):\n",
    "            node = self.root\n",
    "            while self.is_fully_expanded(node) and not self.is_leaf(node):\n",
    "                node = self.best_uct_child(node)\n",
    "\n",
    "            if self.is_expandable(node):\n",
    "                gs = self.select_meta_action(node)\n",
    "                child = self.create_node(self.denoise_subplan(node, gs))\n",
    "                node.add_child(child)\n",
    "                node = child\n",
    "\n",
    "            full_plan = node.trajectory + self.fast_denoising(node.trajectory)\n",
    "            reward = self.evaluate_plan(full_plan)\n",
    "            \n",
    "            # Backpropagation\n",
    "            current_node = node\n",
    "            while current_node is not None:\n",
    "                current_node.visit_count += 1\n",
    "                current_node.value += reward\n",
    "                current_node = current_node.parent\n",
    "\n",
    "        return self.best_uct_child(self.root).trajectory\n",
    "\n",
    "def train_diffusion_model(model, device, dataloader, epochs=5, lr=1e-3):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0.0\n",
    "        for noisy_state, noise_level, clean_state in dataloader:\n",
    "            noisy_state = noisy_state.to(device)\n",
    "            noise_level = noise_level.to(device)\n",
    "            clean_state = clean_state.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(noisy_state, noise_level)\n",
    "            loss = loss_fn(output, clean_state)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch}/{epochs} - Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    state_dim = 4\n",
    "    hidden_dim = 32\n",
    "    num_train_samples = 10000\n",
    "    batch_size = 128\n",
    "    train_epochs = 10\n",
    "    planning_horizon = 10\n",
    "    \n",
    "    # Dataset and model setup\n",
    "    dataset = SyntheticTrajectoryDataset(num_train_samples, state_dim)\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "    \n",
    "    diffusion_model = DiffusionModel(state_dim, hidden_dim).to(device)\n",
    "    print(\"Training diffusion model...\")\n",
    "    train_diffusion_model(diffusion_model, device, dataloader, train_epochs)\n",
    "    print(\"Diffusion model training completed.\\n\")\n",
    "\n",
    "    # Planning setup\n",
    "    goal = torch.ones(state_dim, device=device)\n",
    "    planner = MCTDPlanner(diffusion_model, goal, planning_horizon, state_dim, device)\n",
    "    \n",
    "    print(\"Running planning search...\")\n",
    "    best_traj = planner.search(100)\n",
    "    \n",
    "    # Results display\n",
    "    if not best_traj:\n",
    "        print(\"No valid trajectory found\")\n",
    "    else:\n",
    "        print(f\"\\nPlanned trajectory length: {len(best_traj)}\")\n",
    "        for t, state in enumerate(best_traj):\n",
    "            print(f\"Step {t}: {state.cpu().detach().numpy().round(3)}\")\n",
    "        final_reward = -torch.norm(best_traj[-1] - goal, p=2).item()\n",
    "        print(f\"Final reward (negative distance): {final_reward:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
